{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_02_1_dev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euOZxlIMhstX"
   },
   "source": [
    "# T81-559: Applications of Generative Artificial Intelligence\n",
    "**Module 2: Code Generation**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Yov72PhstY"
   },
   "source": [
    "# Module 2 Material\n",
    "\n",
    "* **Part 2.1: Prompting for Code Generation** [[Video]]() [[Notebook]](t81_559_class_02_1_dev.ipynb)\n",
    "* Part 2.2: Handling Revision Prompts [[Video]]() [[Notebook]](t81_559_class_02_2_multi_prompt.ipynb)\n",
    "* Part 2.3: Using a LLM to Help Debug [[Video]]() [[Notebook]](t81_559_class_02_3_llm_debug.ipynb)\n",
    "* Part 2.4: Tracking Prompts in Software Development [[Video]]() [[Notebook]](t81_559_class_02_4_software_eng.ipynb)\n",
    "* Part 2.5: Limits of LLM Code Generation [[Video]]() [[Notebook]](t81_559_class_02_5_code_gen_limits.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcAUP0c3hstY"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running and maps Google Drive if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsI496h5hstZ",
    "outputId": "4b78d8f4-3b0e-4a47-84a3-10012ba63786"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: using Google CoLab\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.14)\n",
      "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.30 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.31)\n",
      "Requirement already satisfied: langchain-core<0.2.0,>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.40)\n",
      "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.41)\n",
      "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.16.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.37->langchain) (23.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.10.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "try:\n",
    "    from google.colab import drive, userdata\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False\n",
    "\n",
    "# OpenAI Secrets\n",
    "if COLAB:\n",
    "    os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')\n",
    "\n",
    "# Install needed libraries in CoLab\n",
    "if COLAB:\n",
    "    !pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "# 2.1: Prompting for Code Generation\n",
    "\n",
    "## OpenAI for Code Generation\n",
    "\n",
    "LLMs are adept at generating code and can considerably boost programmers' productivity. This technical course requires you to create programs for the assignments. You might wonder if I consider it  \"cheating\" to utilize LLMs to help you write your homework assignments. For this course, I do not consider it cheating to use AI to help you with assignments; I expect such utilization in this course.\n",
    "\n",
    "You can use the same OpenAI LLMs that your OpenAI grants access to for code generation. You also have other options, which may give you access to even greater code generation capabilities, though OpenAI should be sufficient for this class.\n",
    "\n",
    "There are three possible LLM-based code generation tools. All three require additional fees for use.\n",
    "\n",
    "* [GitHub CoPilot](https://github.com/features/copilot)\n",
    "* [ChatGPT](https://chat.openai.com/)\n",
    "* [Amazon CodeWhisperer](https://aws.amazon.com/codewhisperer/)\n",
    "\n",
    "You can use the code below to access OpenAI for code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "TMF-rtxgRAea"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "MODEL = 'codegemma:latest'\n",
    "\n",
    "def generate_code(prompt):\n",
    "  messages = [\n",
    "      SystemMessage(\n",
    "          content=\"You are a helpful assistant that writes reliable computer program code.\"\n",
    "      ),\n",
    "      HumanMessage(content=prompt),\n",
    "  ]\n",
    "\n",
    "  # Initialize the OpenAI LLM with your API key\n",
    "  llm = OllamaLLM(\n",
    "    model=MODEL,\n",
    "    temperature= 0.0,\n",
    "    n= 1)\n",
    "\n",
    "  print(MODEL)\n",
    "  print(\"Model response:\")\n",
    "  output = llm.invoke(messages)\n",
    "  display_markdown(output, raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ClPhLkGldhPt"
   },
   "source": [
    "With the above function defined, you can now generate code. The code below generates a Python function to create a Fibonacci sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "ydaqwgRiH4D6",
    "outputId": "52243a3a-b06b-44e6-a95e-ca398c9865a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codegemma:latest\n",
      "Model response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "def fibonacci(l):\n",
       "    \"\"\"\n",
       "    Returns a fibonacci sequence of a length specified by the parameter l.\n",
       "\n",
       "    Args:\n",
       "        l: The length of the fibonacci sequence.\n",
       "\n",
       "    Returns:\n",
       "        A list containing the fibonacci sequence.\n",
       "    \"\"\"\n",
       "\n",
       "    fib_sequence = [0, 1]\n",
       "    for i in range(2, l):\n",
       "        fib_sequence.append(fib_sequence[i-1] + fib_sequence[i-2])\n",
       "\n",
       "    return fib_sequence\n",
       "```\n",
       "\n",
       "**Example Usage:**\n",
       "\n",
       "```python\n",
       "# Get the length of the fibonacci sequence from the user.\n",
       "l = int(input(\"Enter the length of the fibonacci sequence: \"))\n",
       "\n",
       "# Generate the fibonacci sequence.\n",
       "fib_sequence = fibonacci(l)\n",
       "\n",
       "# Print the fibonacci sequence.\n",
       "print(fib_sequence)\n",
       "```\n",
       "\n",
       "**Output:**\n",
       "\n",
       "```\n",
       "Enter the length of the fibonacci sequence: 10\n",
       "[0, 1, 1, 2, 3, 5, 8, 13, 21, 34]\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_code(\"\"\"Write Python code to return a fibonacci sequence of a length specified by the parameter l.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8fzxOCfgeKUF"
   },
   "source": [
    "## Generating Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "priNIsKGgR7M",
    "outputId": "d9e826bf-f195-4a43-d459-765a473b23fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codegemma:latest\n",
      "Model response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import pandas as pd\n",
       "\n",
       "def loan_amortization(loan_amount, apr, term):\n",
       "    \"\"\"\n",
       "    Calculates the loan amortization schedule.\n",
       "\n",
       "    Args:\n",
       "        loan_amount: The amount of the loan.\n",
       "        apr: The interest rate.\n",
       "        term: The number of months in the loan.\n",
       "\n",
       "    Returns:\n",
       "        A Pandas dataframe containing the loan amortization schedule.\n",
       "    \"\"\"\n",
       "\n",
       "    # Calculate the monthly interest rate.\n",
       "    monthly_interest_rate = apr / 12 / 100\n",
       "\n",
       "    # Calculate the monthly payment.\n",
       "    monthly_payment = loan_amount * (monthly_interest_rate / (1 - (1 + monthly_interest_rate) ** (-term)))\n",
       "\n",
       "    # Create a dictionary of columns for the dataframe.\n",
       "    columns = {\n",
       "        \"month\": [],\n",
       "        \"amount\": [],\n",
       "        \"principal\": [],\n",
       "        \"interest\": [],\n",
       "        \"payment\": [],\n",
       "    }\n",
       "\n",
       "    # Calculate the amortization schedule.\n",
       "    for month in range(1, term + 1):\n",
       "        # Calculate the amount left on the loan.\n",
       "        amount = loan_amount - (monthly_payment * (month - 1))\n",
       "\n",
       "        # Calculate the principal and interest payments.\n",
       "        principal = monthly_payment - amount * monthly_interest_rate\n",
       "        interest = amount * monthly_interest_rate\n",
       "\n",
       "        # Add the data to the dictionary of columns.\n",
       "        columns[\"month\"].append(month)\n",
       "        columns[\"amount\"].append(amount)\n",
       "        columns[\"principal\"].append(principal)\n",
       "        columns[\"interest\"].append(interest)\n",
       "        columns[\"payment\"].append(monthly_payment)\n",
       "\n",
       "    # Create the Pandas dataframe.\n",
       "    df = pd.DataFrame(columns)\n",
       "\n",
       "    return df\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_code(\"\"\"\n",
    "Write a Python function named loan_amortization that accepts these parameters.\n",
    "loan_amount - The amount of the loan.\n",
    "apr - The interest rate.\n",
    "term - The number of months in the loan.\n",
    "The function should return a Pandas dataframe that contains the following columns:\n",
    "month - The current month.\n",
    "amount - The amount left on the loan.\n",
    "principal - The amount payed to the principal this month.\n",
    "interest - The amount paid in interest this month.\n",
    "payment - The total payment this month.\n",
    "Additionally, build a dictionary of columns to create the Pandas dataframe.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dzhI5nTfgeS4",
    "outputId": "3a3c547b-5412-447b-aaec-93283f64e569"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month         amount   principal  interest     payment\n",
      "0      1  100000.000000  275.705440  4.166667  279.872106\n",
      "1      2   99720.127894  275.717101  4.155005  279.872106\n",
      "2      3   99440.255787  275.728762  4.143344  279.872106\n",
      "3      4   99160.383681  275.740424  4.131683  279.872106\n",
      "4      5   98880.511575  275.752085  4.120021  279.872106\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def loan_amortization(loan_amount, apr, term):\n",
    "    \"\"\"\n",
    "    Calculates the loan amortization schedule.\n",
    "\n",
    "    Args:\n",
    "        loan_amount: The amount of the loan.\n",
    "        apr: The interest rate.\n",
    "        term: The number of months in the loan.\n",
    "\n",
    "    Returns:\n",
    "        A Pandas dataframe containing the loan amortization schedule.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the monthly interest rate.\n",
    "    monthly_interest_rate = apr / 12 / 100\n",
    "\n",
    "    # Calculate the monthly payment.\n",
    "    monthly_payment = loan_amount * (monthly_interest_rate / (1 - (1 + monthly_interest_rate) ** (-term)))\n",
    "\n",
    "    # Create a dictionary of columns for the dataframe.\n",
    "    columns = {\n",
    "        \"month\": [],\n",
    "        \"amount\": [],\n",
    "        \"principal\": [],\n",
    "        \"interest\": [],\n",
    "        \"payment\": [],\n",
    "    }\n",
    "\n",
    "    # Calculate the amortization schedule.\n",
    "    for month in range(1, term + 1):\n",
    "        # Calculate the amount left on the loan.\n",
    "        amount = loan_amount - (monthly_payment * (month - 1))\n",
    "\n",
    "        # Calculate the principal and interest payments.\n",
    "        principal = monthly_payment - amount * monthly_interest_rate\n",
    "        interest = amount * monthly_interest_rate\n",
    "\n",
    "        # Add the data to the dictionary of columns.\n",
    "        columns[\"month\"].append(month)\n",
    "        columns[\"amount\"].append(amount)\n",
    "        columns[\"principal\"].append(principal)\n",
    "        columns[\"interest\"].append(interest)\n",
    "        columns[\"payment\"].append(monthly_payment)\n",
    "\n",
    "    # Create the Pandas dataframe.\n",
    "    df = pd.DataFrame(columns)\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "loan_amount = 100000\n",
    "apr = 0.05\n",
    "term = 360\n",
    "\n",
    "amortization_df = loan_amortization(loan_amount, apr, term)\n",
    "\n",
    "print(amortization_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_ZKqu8TeQcm"
   },
   "source": [
    "```\n",
    "Write a Python function named loan_amortization that accepts these parameters.\n",
    "loan_amount - The amount of the loan.\n",
    "apr - The interest rate.\n",
    "term - The number of months in the loan.\n",
    "The function should return a Pandas dataframe that contains the following columns:\n",
    "month - The current month.\n",
    "amount - The amount left on the loan.\n",
    "principal - The amount payed to the principal this month.\n",
    "interest - The amount paid in interest this month.\n",
    "payment - The total payment this month.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t15LDXS9mCI_"
   },
   "source": [
    "## Generating Larger Programs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "q2ixb46lmI4Y",
    "outputId": "b1f03758-6fcd-4b65-91d2-bdad5fdf295a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "codegemma:latest\n",
      "Model response:\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "import torch\n",
       "import torch.nn as nn\n",
       "import pandas as pd\n",
       "from PIL import Image\n",
       "from torchvision.transforms import transforms\n",
       "\n",
       "# Load the training data\n",
       "train_df = pd.read_csv('/kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/train.csv')\n",
       "\n",
       "# Define the data transformation\n",
       "transform = transforms.Compose([\n",
       "    transforms.Resize((224, 224)),\n",
       "    transforms.ToTensor(),\n",
       "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
       "])\n",
       "\n",
       "# Define the neural network\n",
       "class AgeNet(nn.Module):\n",
       "    def __init__(self):\n",
       "        super().__init__()\n",
       "        self.model = torch.hub.load('pytorch/vision:v0.6.0', 'resnet18', pretrained=True)\n",
       "        self.model.fc = nn.Linear(self.model.fc.in_features, 1)\n",
       "\n",
       "    def forward(self, x):\n",
       "        return self.model(x)\n",
       "\n",
       "# Create the neural network\n",
       "model = AgeNet().cuda()\n",
       "\n",
       "# Define the loss function and optimizer\n",
       "criterion = nn.MSELoss()\n",
       "optimizer = torch.optim.Adam(model.parameters())\n",
       "\n",
       "# Train the neural network\n",
       "epochs = 10\n",
       "early_stopping_counter = 0\n",
       "best_val_loss = float('inf')\n",
       "\n",
       "for epoch in range(epochs):\n",
       "    # Train the model\n",
       "    model.train()\n",
       "    for filename, age in zip(train_df['filename'], train_df['age']):\n",
       "        image = Image.open(f'/kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/faces/{filename}')\n",
       "        image = transform(image).cuda()\n",
       "        age = torch.tensor([age]).cuda()\n",
       "\n",
       "        optimizer.zero_grad()\n",
       "        output = model(image)\n",
       "        loss = criterion(output, age)\n",
       "        loss.backward()\n",
       "        optimizer.step()\n",
       "\n",
       "    # Validate the model\n",
       "    model.eval()\n",
       "    val_loss = 0\n",
       "    for filename, age in zip(train_df['filename'], train_df['age']):\n",
       "        image = Image.open(f'/kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/faces/{filename}')\n",
       "        image = transform(image).cuda()\n",
       "        age = torch.tensor([age]).cuda()\n",
       "\n",
       "        output = model(image)\n",
       "        val_loss += criterion(output, age)\n",
       "\n",
       "    val_loss /= len(train_df)\n",
       "\n",
       "    # Early stopping\n",
       "    if val_loss < best_val_loss:\n",
       "        best_val_loss = val_loss\n",
       "        early_stopping_counter = 0\n",
       "    else:\n",
       "        early_stopping_counter += 1\n",
       "\n",
       "    if early_stopping_counter > 3:\n",
       "        break\n",
       "\n",
       "# Load the test data\n",
       "test_df = pd.read_csv('/kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/test.csv')\n",
       "\n",
       "# Generate the submit dataframe\n",
       "submit_df = pd.DataFrame({'id': test_df['id']})\n",
       "\n",
       "# Predict the ages\n",
       "model.eval()\n",
       "for filename in test_df['filename']:\n",
       "    image = Image.open(f'/kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/faces/{filename}')\n",
       "    image = transform(image).cuda()\n",
       "\n",
       "    output = model(image)\n",
       "    submit_df = submit_df.append({'id': filename, 'age': output.item()}, ignore_index=True)\n",
       "\n",
       "# Save the submit dataframe\n",
       "submit_df.to_csv('submission.csv', index=False)\n",
       "```"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generate_code(\"\"\"\n",
    "Create a PyTorch GPU-enabled neural network for a Kaggle competition that asks me to predict the age of people in provided images.\n",
    "The images are stored at this path: /kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age.\n",
    "The training data is in the file: /kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/train.csv.\n",
    "The training data has 3 columns, id, filename, and age. The field age is the target, to be predicted, numeric age in years of\n",
    "the person. The file contains the filename of the image that corresponds to each row, the images are named 1.jpg, 2.jpg, etc,\n",
    "which corresponds to both the id and the filename fields. There is also a test dataset that we must generate a submission\n",
    "dataframe for. The test data is in the file /kaggle/input/applications-of-deep-learning-wustl-spring-2024/faces-age/test.csv,\n",
    "and has the id and filename columns, but we need to generate a submit dataframe with just id and age(the prediction). Train the neural network, use early stopping and generate the submit dataframe.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3TjZs_TRht1n"
   },
   "source": [
    "# Module 2 Assignment\n",
    "\n",
    "You can find the first assignment here: [assignment 2](https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class2.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "generative-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
