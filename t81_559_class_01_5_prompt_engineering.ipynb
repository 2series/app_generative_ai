{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "whjsJasuhstV"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/jeffheaton/app_generative_ai/blob/main/t81_559_class_01_5_prompt_engineering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euOZxlIMhstX"
   },
   "source": [
    "# T81-559: Applications of Deep Neural Networks\n",
    "**Module 1: Course Overview**\n",
    "* Instructor: [Jeff Heaton](https://sites.wustl.edu/jeffheaton/), McKelvey School of Engineering, [Washington University in St. Louis](https://engineering.wustl.edu/Programs/Pages/default.aspx)\n",
    "* For more information visit the [class website](https://sites.wustl.edu/jeffheaton/t81-558/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d4Yov72PhstY"
   },
   "source": [
    "# Module 1 Material\n",
    "\n",
    "* Part 1.1: Course Overview [[Video]]() [[Notebook]](t81_558_class_01_1_overview.ipynb)\n",
    "* Part 1.2: Generative AI Overview [[Video]]() [[Notebook]](t81_558_class_01_2_genai.ipynb)\n",
    "* Part 1.3: Introduction to OpenAI [[Video]]() [[Notebook]](t81_558_class_01_3_openai.ipynb)\n",
    "* Part 1.4: Introduction to LangChain [[Video]]() [[Notebook]](t81_558_class_01_4_langchain.ipynb)\n",
    "* **Part 1.5: Prompt Engineering** [[Video]]() [[Notebook]](t81_558_class_01_5_prompt_engineering.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AcAUP0c3hstY"
   },
   "source": [
    "# Google CoLab Instructions\n",
    "\n",
    "The following code ensures that Google CoLab is running and maps Google Drive if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xsI496h5hstZ",
    "outputId": "cbc72cd3-dfc0-4ba1-b88d-e654b514bba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: not using Google CoLab\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    COLAB = True\n",
    "    print(\"Note: using Google CoLab\")\n",
    "except:\n",
    "    print(\"Note: not using Google CoLab\")\n",
    "    COLAB = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC9A-LaYhsta"
   },
   "source": [
    "# Part 1.5: Prompt Engineering\n",
    "\n",
    "## Zero-Shot, Few-Shot and One-Shot Prompting\n",
    "\n",
    "In the evolving landscape of artificial intelligence, particularly in the domain of natural language processing and machine learning, the concept of prompt engineering emerges as a pivotal strategy for enhancing the performance of models like ChatGPT. This approach is crucial when dealing with scenarios where data is scarce or entirely absent for certain classes. Here, we delve into three innovative learning paradigms—One-shot learning, Few-shot learning, and Zero-shot learning—each tailored to overcome the challenges of data scarcity by leveraging the inherent adaptability and knowledge encapsulation of models like ChatGPT. These methodologies not only underscore the versatility of large language models but also highlight the importance of prompt engineering in harnessing their full potential.\n",
    "\n",
    "* One-shot Learning: The Art of Instant Adaptation\n",
    "* Few-shot Learning: Leveraging Minimal Data\n",
    "* Zero-shot Learning: Predicting the Unknown\n",
    "\n",
    "One-shot learning represents a scenario where the model is presented with a singular instance of labeled data for each new class. The quintessence of this approach lies in its challenge: to generalize and make accurate predictions about new classes from a mere glance. This method demands a highly refined model capable of extracting and applying the vast nuances of knowledge it has acquired from its training on a diverse dataset. In the context of prompt engineering, the focus shifts to designing prompts that can effectively communicate the essence of the new class through this lone example. The crafted prompt must guide the model in recognizing the unique characteristics of this example and applying its generalized understanding to make predictions about unseen instances of the class.\n",
    "\n",
    "Few-shot learning takes a step further by providing a handful of labeled examples for each new class, bridging the gap between theoretical knowledge and practical application. This approach challenges the model to adapt its pre-existing knowledge framework to accommodate new information from a minimal dataset. In prompt engineering, the strategy involves creating prompts that not only highlight the specific attributes of the examples provided but also encourage the model to draw parallels and distinctions with its pre-existing knowledge base. The aim is to enhance the model's ability to extrapolate from these few examples and apply its learned insights to accurately predict the characteristics of new instances within the same class.\n",
    "\n",
    "Zero-shot learning ventures into the realm of the unknown, where no labeled data is available for new classes. The model is expected to rely solely on its pre-existing knowledge and the relationships it understands between known classes to make inferences about entirely new categories. This learning paradigm exemplifies the power of semantic understanding and the ability to apply abstract concepts across different contexts. In prompt engineering for zero-shot learning, the emphasis is on crafting prompts that effectively communicate the context and expected relationships of new classes in relation to known ones. By leveraging semantic similarities and the model's comprehensive understanding of language and concepts, it is possible to guide the model towards making informed predictions about these new, unseen classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GR-0hiBlhstb"
   },
   "source": [
    "# Module 1 Assignment\n",
    "\n",
    "You can find the first assignment here: [assignment 1](https://github.com/jeffheaton/app_deep_learning/blob/main/assignments/assignment_yourname_class1.ipynb)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "t81_558_class_01_1_overview.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (torch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
